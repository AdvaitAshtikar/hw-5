},
forward = function(x){
x %>%
self$hidden1() %>% self$activation() %>%
self$hidden2() %>% self$activation() %>%
self$hidden3() %>% self$activation() %>%
self$output() %>% self$sigmoid()
}
)
generate_three_spirals <- function(){
set.seed(42)
n <- 500
noise <- 0.2
t <- (1:n) / n * 2 * pi
x1 <- c(
t * (sin(t) + rnorm(n, 0, noise)),
t * (sin(t + 2 * pi/3) + rnorm(n, 0, noise)),
t * (sin(t + 4 * pi/3) + rnorm(n, 0, noise))
)
x2 <- c(
t * (cos(t) + rnorm(n, 0, noise)),
t * (cos(t + 2 * pi/3) + rnorm(n, 0, noise)),
t * (cos(t + 4 * pi/3) + rnorm(n, 0, noise))
)
y <- as.factor(
c(
rep(0, n),
rep(1, n),
rep(2, n)
)
)
return(tibble(x1=x1, x2=x2, y=y))
}
df <- generate_three_spirals()
plot(
df$x1, df$x2,
col = df$y,
pch = 20
)
sessionInfo()
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_params(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_soze = 128,
shuffle = TRUE
),
verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_soze = 128,
shuffle = TRUE
),
verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = 2, q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_soze = 128,
shuffle = TRUE
),
verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = 2, q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_soze = 128,
shuffle = TRUE
),
verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting
)
NNet <- nn_module(
initialize = function(p, q1, q2, q3){
self$hidden1 <- nn_linear(p, q1)
self$hidden2 <- nn_linear(q1, q2)
self$hidden3 <- nn_linear(q2, q3)
self$output <- nn_linear(q3, 1)
self$activation <- nn_relu()
self$sigmoid <- nn_sigmoid()
},
forward = function(x){
x %>%
self$hidden1() %>% self$activation() %>%
self$hidden2() %>% self$activation() %>%
self$hidden3() %>% self$activation() %>%
self$output() %>% self$sigmoid()
}
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = 2, q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_soze = 128,
shuffle = TRUE
),
verbose = FALSE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = 2, q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_soze = 128,
shuffle = TRUE
),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = 2, q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
as.matrix(df_train[, -1]),
as.numeric(df[, 1]) - 1
),
dataloader_options = list(
batch_size = 128,
shuffle = TRUE
),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
df <- read_csv("data/spam.csv") %>%
select(-contains("Unnamed")) %>%
mutate_if(is.character, as.factor) %>%
rename_all(tolower) %>%
na.omit()
path <- "data/spam.csv"
df <- read_csv(path) %>%
select(-contains("Unnamed")) %>%
mutate_if(is.character, as.factor) %>%
rename_all(tolower) %>%
na.omit()
path <- "data/spambase.csv"
df <- read_csv(path) %>%
select(-contains("Unnamed")) %>%
mutate_if(is.character, as.factor) %>%
rename_all(tolower) %>%
na.omit()
path <- "data/spambase.csv"
df <- read_csv(path) %>%
select(-contains("Unnamed")) %>%
mutate_if(is.character, as.factor) %>%
rename_all(tolower) %>%
na.omit()
df %>% head
set.seed(42)
test_ind <- sample(
1:nrow(df),
floor( nrow(df)/10 ),
replace=FALSE
)
df_train <- df[-test_ind, ]
df_test  <- df[test_ind, ]
overview <- function(pred_class, true_class) {
accuracy <- mean(pred_class == true_class)
error <- 1 - accuracy
true_positives <- sum(pred_class == "1" & true_class == "1")
true_negatives <- sum(pred_class == "0" & true_class == "0")
false_positives <- sum(pred_class == "1" & true_class == "0")
false_negatives <- sum(pred_class == "0" & true_class == "1")
true_positive_rate <- false_positives / (false_positives + true_negatives)
false_positive_rate <- false_negatives / (false_negatives + true_positives)
return(
data.frame(
accuracy = accuracy,
error = error,
true_positive_rate = true_positive_rate,
false_positive_rate = false_positive_rate
)
)
}
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
library(dplyr)
library(readr)
library(tidyr)
library(purrr)
library(broom)
library(magrittr)
library(corrplot)
library(caret)
library(rpart)
library(rpart.plot)
library(e1071)
library(torch)
library(luz)
path <- "data/housing.csv"
df <- read_csv(path) %>%
mutate_if(is.character, as.factor) %>%
rename_all(tolower) %>%
na.omit()
df %>% head
df %>%
select_if(is.numeric) %>%
cor() %>%
corrplot(type = "upper", method = "color", order = "hclust")
set.seed(42)
test_ind <- sample(
1:nrow(df),
floor( nrow(df)/10 ),
replace=FALSE
)
df_train <- df[-test_ind, ]
df_test  <- df[test_ind, ]
lm_fit <- lm(median_house_value ~ latitude + longitude + housing_median_age + total_rooms + total_bedrooms + population + median_income + ocean_proximity, data = df_train)
summary(lm_fit)
rmse <- function(y, yhat) {
sqrt(mean((y - yhat)^2))
}
lm_predictions <- predict(lm_fit, newdata = df_test)
rmse(df_test$median_house_value, lm_predictions)
rpart_fit <- rpart(median_house_value ~ latitude + longitude + housing_median_age + total_rooms + total_bedrooms + population + median_income + ocean_proximity, data = df_train)
rpart_predictions <- predict(rpart_fit, newdata = df_test)
rpart.plot(rpart_fit)
rpart_predictions <- predict(rpart_fit, newdata = df_test)
rmse(df_test$median_house_value, rpart_predictions)
svm_fit <- svm(median_house_value ~ latitude + longitude + housing_median_age + total_rooms + total_bedrooms + population + median_income + ocean_proximity, data = df_train, kernel = "radial")
svm_predictions <- predict(svm_fit, newdata = df_test)
rmse(df_test$median_house_value, svm_predictions)
NNet <- nn_module(
initialize = function(p, q1, q2, q3){
self$hidden1 <- nn_linear(p, q1)
self$hidden2 <- nn_linear(q1, q2)
self$hidden3 <- nn_linear(q2, q3)
self$output <- nn_linear(q3, 1)
self$activation <- nn_relu()
self$sigmoid <- nn_sigmoid()
},
forward = function(x){
x %>%
self$hidden1() %>% self$activation() %>%
self$hidden2() %>% self$activation() %>%
self$hidden3() %>% self$activation() %>%
self$output() %>% self$sigmoid()
}
)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.005
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.005
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
nnet_fit <- NNet %>%
setup(
loss = nn_bce_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.05
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
plot(nnet_fit)
